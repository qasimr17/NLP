{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import spacy \n",
    "import string \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@USAirways Is there a phone line to call into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united Bag was finally delivered and intact. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@usairways Thanks to Kevin and team at F38ish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Yes, talked to them. FLL says is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral  @USAirways Is there a phone line to call into ...\n",
       "1          positive  @united Bag was finally delivered and intact. ...\n",
       "2          positive  @usairways Thanks to Kevin and team at F38ish ...\n",
       "3          negative  @AmericanAir Yes, talked to them. FLL says is ...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split \n",
    "\n",
    "df.iloc[:, 0].value_counts()\n",
    "# Note that there are three imbalanced sentiment classes - with the negative class having the highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relevant classes are: ['negative' 'neutral' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@USAirways Is there a phone line to call into ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united Bag was finally delivered and intact. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@usairways Thanks to Kevin and team at F38ish ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Yes, talked to them. FLL says is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral  @USAirways Is there a phone line to call into ...   \n",
       "1          positive  @united Bag was finally delivered and intact. ...   \n",
       "2          positive  @usairways Thanks to Kevin and team at F38ish ...   \n",
       "3          negative  @AmericanAir Yes, talked to them. FLL says is ...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "   target_class  \n",
       "0             1  \n",
       "1             2  \n",
       "2             2  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we need to convert these classes into numbers \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = df.iloc[:, 0]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(labels)\n",
    "print(f\"The relevant classes are: {label_encoder.classes_}\")\n",
    "\n",
    "df['target_class'] = label_encoder.transform(labels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USAirways Is there a phone line to call into ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@united Bag was finally delivered and intact. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@usairways Thanks to Kevin and team at F38ish ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AmericanAir Yes, talked to them. FLL says is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target_class\n",
       "0  @USAirways Is there a phone line to call into ...             1\n",
       "1  @united Bag was finally delivered and intact. ...             2\n",
       "2  @usairways Thanks to Kevin and team at F38ish ...             2\n",
       "3  @AmericanAir Yes, talked to them. FLL says is ...             0\n",
       "4  @VirginAmerica and it's a really big bad thing...             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain the relevant columns \n",
    "df = df.drop(['airline_sentiment'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    62.691257\n",
      "1    21.168033\n",
      "2    16.140710\n",
      "Name: target_class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to split the data into train and test but preserving the ratio of classes\n",
    "ratios = lambda x : (x.value_counts() / len(x)) * 100\n",
    "print(ratios(df.target_class))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df.text, df.target_class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.2\n",
      "Train Data:\n",
      "0    62.696380\n",
      "1    21.166325\n",
      "2    16.137295\n",
      "Name: target_class, dtype: float64,\n",
      "Test data:\n",
      "0    62.670765\n",
      "1    21.174863\n",
      "2    16.154372\n",
      "Name: target_class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train) / len(X), len(X_test) / len(X))\n",
    "# Correct 80-20 split\n",
    "\n",
    "# Also, we note that the class ratios have been preserved after the split as well:\n",
    "print(f\"Train Data:\\n{ratios(y_train)},\\nTest data:\\n{ratios(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load English library from spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# list of stop words \n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# punctuations\n",
    "punctuations = string.punctuation + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLS and @ mentions \n",
    "remove_urls = lambda text: re.sub(rf\"\\S*https?:\\S*|@\\S*\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "# remove emojis\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer \n",
    "def tokenizer(text):\n",
    "\n",
    "    # Remove unwanted URLs\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    tokens = nlp(text)\n",
    "    \n",
    "    # Lemmatize each token maintain relevant case\n",
    "    tokens = [word.lemma_.strip().lower() if word.pos_ != \"PROPN\" else word.lemma_.strip() for word in tokens]\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
    "\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USAirways Is there a phone line to call into that isn't being affected by \"bad weather\"? Trying to book a vacation, here... 👀\n",
      "['phone', 'line', 'affect', 'bad', 'weather', 'try', 'book', 'vacation']\n"
     ]
    }
   ],
   "source": [
    "# We can see how a sample text is preprocessed \n",
    "\n",
    "# Before preprocessing \n",
    "tweet = df['text'].iloc[0]\n",
    "print(tweet)\n",
    "\n",
    "# After preprocessing \n",
    "print(tokenizer(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, tokenizing the entire array of tweets\n",
    "cleaned_words = X_train.apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 2879),\n",
       " ('thank', 1288),\n",
       " ('hour', 844),\n",
       " ('cancel', 787),\n",
       " ('service', 754),\n",
       " ('delay', 738),\n",
       " ('time', 728),\n",
       " ('help', 711),\n",
       " ('customer', 700),\n",
       " ('fly', 585)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution\n",
    "\n",
    "# Check most 10 most common words after cleaning \n",
    "from collections import Counter \n",
    "Counter(x for xs in cleaned_words for x in set(xs)).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model \n",
    "\n",
    "To create a numeric feature representation of these tweets, we employ the bag of words model using the custom tokenizer function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vector = CountVectorizer(tokenizer=tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight' 'good' 'time']\n",
      "[[1 1 0]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "sample_tweets = ['The flight was good', 'The flight was on time']\n",
    "bow_vector.fit_transform(sample_tweets).toarray()\n",
    "\n",
    "print(bow_vector.get_feature_names_out())\n",
    "print(bow_vector.fit_transform(sample_tweets).toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification pipeline\n",
    "\n",
    "We can combine our preprocessing tasks and machine learning classification into a single pipeline using sklearn's Pipeline module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(multi_class=\"multinomial\", max_iter=500)\n",
    "pipeline = Pipeline([('bow_vector', bow_vector),('classifier', logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow_vector',\n",
       "                 CountVectorizer(tokenizer=<function tokenizer at 0x0000019360F9A9D0>)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=500, multi_class='multinomial'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7797131147540983\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Accuracy: {(y_hat == y_test).sum() / len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.844     0.877     0.860      1835\n",
      "     neutral      0.600     0.573     0.586       620\n",
      "    positive      0.743     0.672     0.706       473\n",
      "\n",
      "    accuracy                          0.780      2928\n",
      "   macro avg      0.729     0.707     0.717      2928\n",
      "weighted avg      0.776     0.780     0.777      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, y_hat, digits=3, target_names=['negative', 'neutral', 'positive']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c99bd3d91a4b91323b9437e92699dbf82cc6ba26dc500b79c067afe17d1503df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('handson_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
